{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/teo/userdata/SejongMusic\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "from omegaconf import OmegaConf\n",
    "from fractions import Fraction\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "from music21 import converter, stream, note as m21_note \n",
    "\n",
    "from sejong_music import model_zoo\n",
    "from sejong_music.yeominrak_processing import AlignedScore, SamplingScore, pack_collate, ShiftedAlignedScore, TestScore, TestScoreCPH, Tokenizer, SimpleNote\n",
    "from sejong_music.model_zoo import QkvAttnSeq2seq, get_emb_total_size, QkvAttnSeq2seqMore\n",
    "from sejong_music.decode import MidiDecoder\n",
    "from torch.utils.data import  DataLoader\n",
    "\n",
    "from make_inference import get_measure_shifted_output, prepare_input_for_next_part, get_measure_specific_output, fix_measure_idx, recover_beat, fill_in_source\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dir = 'outputs/2024-03-08/00-27-49/wandb/run-20240308_002750-ui4ko24t/files/checkpoints'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = torch.load(f'{state_dir}/best_pitch_sim_model.pt')\n",
    "\n",
    "config = OmegaConf.load(f'{state_dir}/config.yaml')\n",
    "tokenizer = Tokenizer(parts=None, feature_types=None, json_fn=f'{state_dir}/tokenizer_vocab.json')\n",
    "# config = get_emb_total_size(config)\n",
    "device = 'cpu'\n",
    "# val_dataset = ShiftedAlignedScore(is_valid= True, slice_measure_num=4, feature_types=config.model.features)\n",
    "# valid_loader = DataLoader(val_dataset, batch_size=4, collate_fn=pack_collate, shuffle=False)\n",
    "model = getattr(model_zoo, config.model_class)(tokenizer, config.model).to(device)\n",
    "model.is_condition_shifted = True\n",
    "model.load_state_dict(state)\n",
    "model.eval()\n",
    "\n",
    "decoder = MidiDecoder(tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestScoreCPH2(TestScore):\n",
    "  def __init__(self, xml_path='0_edited.musicxml', valid_measure_num=..., slice_measure_num=2, is_valid=False, use_pitch_modification=False, pitch_modification_ratio=0, min_meas=3, max_meas=6, transpose=0, feature_types=..., sampling_rate=None) -> None:\n",
    "    super().__init__(xml_path, valid_measure_num, slice_measure_num, is_valid, use_pitch_modification, pitch_modification_ratio, min_meas, max_meas, transpose, feature_types, sampling_rate)\n",
    "\n",
    "\n",
    "  def fix_part_by_rule(self):\n",
    "    flattened_notes = [SimpleNote(note) for measure in self.parts[0].measures for note in measure]\n",
    "              \n",
    "    measure_shifted_notes = []\n",
    "    for note in flattened_notes:\n",
    "\n",
    "      ### pitch modification\n",
    "      if note.pitch == 51:\n",
    "        note.pitch = 52 # 51 is error\n",
    "      if note.pitch == 39:\n",
    "        note.pitch = 40\n",
    "      if note.pitch == 56:\n",
    "        note.pitch = 57\n",
    "      if note.pitch == 57:\n",
    "        note.pitch = 45\n",
    "      measure_shifted_notes.append(note)\n",
    "\n",
    "\n",
    "    # make measure list\n",
    "    note_by_measure = []\n",
    "    temp_measure = []\n",
    "    prev_measure_number = 0\n",
    "    for note in measure_shifted_notes:\n",
    "      if note.measure_number != prev_measure_number:\n",
    "        note_by_measure.append(temp_measure)\n",
    "        temp_measure = []\n",
    "        prev_measure_number = note.measure_number\n",
    "      temp_measure.append(note)\n",
    "    note_by_measure.append(temp_measure)\n",
    "\n",
    "    self.parts[0].measures = note_by_measure\n",
    "    self.measure_features = [self.get_feature(i) for i in range(len(self.parts))]\n",
    "\n",
    "    part_zero = self.measure_features[0].copy()\n",
    "    for measure in part_zero:\n",
    "      for note in measure:\n",
    "        note[2] *= 2\n",
    "        note[3] *= 2\n",
    "    self.measure_features[0] = part_zero\n",
    "    self.offset_list[0] *= 2\n",
    "\n",
    "test_set = TestScoreCPH2(xml_path=\"music_score/chwipunghyeong.musicxml\", is_valid=True, \n",
    "                        #  valid_measure_num=[i for i in range(133)], \n",
    "                        valid_measure_num='entire',\n",
    "                        slice_measure_num=4, transpose=+8, feature_types=config.model.features)\n",
    "test_set.tokenizer = tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set =  TestScoreCPH(xml_path=\"music_score/chwipunghyeong.musicxml\", is_valid=True, \n",
    "                        #  valid_measure_num=[i for i in range(133)], \n",
    "                        valid_measure_num='entire',\n",
    "                        slice_measure_num=4, transpose=+8, feature_types=config.model.features)\n",
    "test_set.tokenizer = tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pad',\n",
       " 'start',\n",
       " 'end',\n",
       " 34.0,\n",
       " 36.0,\n",
       " 39.0,\n",
       " 41.0,\n",
       " 43.0,\n",
       " 44.0,\n",
       " 46.0,\n",
       " 48.0,\n",
       " 49.0,\n",
       " 51.0,\n",
       " 53.0,\n",
       " 55.0,\n",
       " 56.0,\n",
       " 58.0,\n",
       " 60.0,\n",
       " 63.0]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab['pitch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pad',\n",
       " 'start',\n",
       " 'end',\n",
       " 8.0,\n",
       " 0.0,\n",
       " Fraction(1, 3),\n",
       " 0.5,\n",
       " Fraction(2, 3),\n",
       " 1.0,\n",
       " 1.5,\n",
       " 1.6666666666666665,\n",
       " 2.0,\n",
       " 2.5,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 5.0,\n",
       " 6.0]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if 6.0 not in tokenizer.vocab['duration']:\n",
    "  tokenizer.vocab['duration'].append(6.0)\n",
    "  tokenizer.tok2idx['duration'][6.0] = len(tokenizer.tok2idx['duration'])\n",
    "  \n",
    "  # add weight to the model embedding\n",
    "  dup_weight = model.encoder.emb.layers[2].weight[tokenizer.tok2idx['duration'][5.0]]\n",
    "\n",
    "  model.encoder.emb.layers[2].weight.data = torch.cat([model.encoder.emb.layers[2].weight, dup_weight.unsqueeze(0)], dim=0)\n",
    "\n",
    "tokenizer.vocab['duration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  1,  1,  1,  1],\n",
       "        [ 0, 12, 11,  3,  3,  3],\n",
       "        [ 0, 13, 13,  7,  5,  3],\n",
       "        [ 0, 12, 13, 19,  3,  3],\n",
       "        [ 0, 12, 11,  3,  3,  4],\n",
       "        [ 0, 12, 16,  7,  5,  4],\n",
       "        [ 0, 12, 11,  3,  3,  5],\n",
       "        [ 0, 13,  8,  7,  5,  5],\n",
       "        [ 0, 12,  6, 11,  4,  5],\n",
       "        [ 0, 10,  9, 13,  5,  5],\n",
       "        [ 0,  9, 11, 19,  3,  5],\n",
       "        [ 0, 10,  8, 25,  5,  5],\n",
       "        [ 0,  2,  2,  2,  2,  2]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/130 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130/130 [00:01<00:00, 67.66it/s]\n"
     ]
    }
   ],
   "source": [
    "test_set.tokenizer = tokenizer\n",
    "print(\"Start inference\")\n",
    "score = stream.Score(id='mainScore')\n",
    "\n",
    "prev_generation = None\n",
    "outputs = []\n",
    "source_part = stream.Part()\n",
    "merged_part = stream.Part() \n",
    "srcs = []\n",
    "start_idx = 1\n",
    "target_idx = 2\n",
    "\n",
    "for i in tqdm(range(len(test_set))):\n",
    "  sample = test_set[i]\n",
    "  sample[:,0] = start_idx # regard as era 1\n",
    "  src, output_decoded, (attention_map, output, new_out) = model.shifted_inference(sample, target_idx, prev_generation=prev_generation)\n",
    "  if i % test_set.slice_measure_number == 0:\n",
    "    srcs.append(src)\n",
    "  if i == 0:\n",
    "    sel_out = torch.cat([output[0:1]] + [get_measure_specific_output(output, i) for i in range(3,6)], dim=0)\n",
    "  else:\n",
    "    sel_out = get_measure_specific_output(output, 5)\n",
    "    sel_duration = sum([x[2] for x in model.converter(sel_out)])\n",
    "    if abs(sel_duration - model.tokenizer.measure_duration[target_idx]) > 0.001:\n",
    "      print(f'Generated duration: {sel_duration}, target idx: {target_idx}, Running Alt model inference')\n",
    "      src, output_decoded, (attention_map, output, new_out) = model_alt.shifted_inference(sample, target_idx, prev_generation=prev_generation)\n",
    "      sel_out = get_measure_specific_output(output, 5) \n",
    "      sel_duration = sum([x[2] for x in model.converter(sel_out)])\n",
    "      assert abs(sel_duration - model.tokenizer.measure_duration[target_idx]) < 0.001\n",
    "  prev_generation = get_measure_shifted_output(output)\n",
    "  outputs.append(sel_out)\n",
    "\n",
    "srcs.append(fill_in_source(src, i % test_set.slice_measure_number))\n",
    "source_converted = [y for x in srcs for y in x]\n",
    "source_part = decoder(source_converted)\n",
    "outputs.append(get_measure_specific_output(output, 6)) # add last measure\n",
    "outputs_tensor = torch.cat(outputs, dim=0)\n",
    "final_midi = decoder(model.converter(outputs_tensor))\n",
    "score.insert(0, source_part)\n",
    "score.insert(0, final_midi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/teo/userdata/SejongMusic/gen_results/chwipunghyeong_testest4.musicxml')"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score.write('musicxml', fp='gen_results/chwipunghyeong_testest4.musicxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tok2idx[tokenizer.key_types[1]][53.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['index',\n",
       " 'pitch',\n",
       " 'duration',\n",
       " 'offset',\n",
       " 'dynamic',\n",
       " 'measure_idx',\n",
       " 'offset_fraction']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.key_types"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SejongMusic-0Xd-sAL0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
