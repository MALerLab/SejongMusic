{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ..\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sejong_music.era_inference import EraTransformer\n",
    "\n",
    "era_transformer = EraTransformer('wandb/run-20240405_155230-52nfcuf5/files/checkpoints')\n",
    "gen_str = open('music_score/chwipunghyeong_gen.txt').read()\n",
    "notes_set, score = era_transformer.infer_on_gen_str(gen_str, 'piri', 30, onset_ratio=1.2)\n",
    "score.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sejong_music.jg_code import JeongganPiece\n",
    "\n",
    "inst = 'piri'\n",
    "idx = 0\n",
    "self = era_transformer\n",
    "\n",
    "piece = JeongganPiece(None, gen_str=gen_str, inst_list=[inst])\n",
    "x = piece.convert_tokens_to_roll(piece.sliced_parts_by_measure[idx][inst], inst)\n",
    "x = self.convert_to_input_format(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7171, 0.6460, 0.5830, 0.5189, 0.4746, 0.1499, 0.0526, 0.3584, 0.3573,\n",
       "        0.1712, 0.2594, 0.2960, 0.1404, 0.2429, 0.2827],\n",
       "       grad_fn=<SqueezeBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from sejong_music.jg_to_staff_converter import JGToStaffConverter\n",
    "from sejong_music.era_align_utils import EraAlignPairSet\n",
    "\n",
    "tokens = piece.sliced_parts_by_measure[idx][inst]\n",
    "notes = JGToStaffConverter.convert_to_notes(tokens)\n",
    "JGToStaffConverter.get_duration_of_notes(notes)\n",
    "JGToStaffConverter().create_m21_notes(notes)\n",
    "\n",
    "features = []\n",
    "for note in notes:\n",
    "  note_feature = ['era1', f'pitch{note.midi_pitch}', EraAlignPairSet.convert_duration(note.duration/2), 'strong']\n",
    "  features.append(note_feature)\n",
    "\n",
    "masker_input = torch.LongTensor(era_transformer.masker.tokenizer(features))\n",
    "era_transformer.masker.align_model(masker_input.unsqueeze(0)).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "era_transformer.masker.tokenizer.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_vocab = []\n",
    "for word in era_transformer.masker.tokenizer.vocab:\n",
    "  if 'pitch' not in word:\n",
    "    new_vocab.append(word)\n",
    "  elif word == 'pitch0':\n",
    "    new_vocab.append(word)\n",
    "  else:\n",
    "    new_vocab.append(f'pitch{int(word[5:])+12}')\n",
    "new_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=0\n",
    "inst = 'piri'\n",
    "self = era_transformer\n",
    "\n",
    "piece = JeongganPiece(None, gen_str=gen_str, inst_list=[inst])\n",
    "x = piece.convert_tokens_to_roll(piece.sliced_parts_by_measure[idx][inst], inst)\n",
    "x = self.convert_to_input_format(x)\n",
    "x, loss_mask = self.masker.mask_except_note_onset(x)\n",
    "x, loss_mask = self.aug_form_to_input_form(x), self.aug_form_to_input_form(loss_mask)\n",
    "x = self.unmask_pitch_and_ornaments(x.to(self.device), loss_mask.to(self.device), 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roll = self.tokenizer.decode(x)\n",
    "roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import datetime\n",
    "import copy\n",
    "from pathlib import Path\n",
    "from omegaconf import OmegaConf\n",
    "from fractions import Fraction\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "from music21 import converter, stream, note as m21_note \n",
    "import numpy as np\n",
    "\n",
    "from sejong_music import model_zoo, jg_code, inference\n",
    "from sejong_music.yeominrak_processing import OrchestraScoreSeq, ShiftedAlignedScore, Tokenizer\n",
    "from sejong_music.model_zoo import JeongganTransSeq2seq, JeongganBERT\n",
    "from sejong_music.decode import MidiDecoder, OrchestraDecoder\n",
    "from sejong_music.inference_utils import prepare_input_for_next_part, get_measure_specific_output, fix_measure_idx, fill_in_source, get_measure_shifted_output, recover_beat, round_number\n",
    "from sejong_music.inference import JGInferencer\n",
    "from sejong_music.jg_to_staff_converter import JGToStaffConverter\n",
    "from sejong_music.jg_code import JeongganDataset, JeongganTokenizer, JGMaskedDataset, JeongganPiece\n",
    "from sejong_music.full_inference import Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dir = Path('wandb/run-20240405_155230-52nfcuf5/files/checkpoints')\n",
    "config_fn = state_dir / 'config.yaml'\n",
    "json_fn = state_dir / 'tokenizer_vocab.json'\n",
    "ckpt_fn = state_dir / 'inst_0' / 'iter46400_model.pt'\n",
    "\n",
    "assert config_fn.exists() and json_fn.exists() and ckpt_fn.exists()\n",
    "\n",
    "config = OmegaConf.load(config_fn)\n",
    "tokenizer = JeongganTokenizer(None, None, True, json_fn=json_fn)\n",
    "model = JeongganBERT(tokenizer=tokenizer, config=config.model)\n",
    "model.load_state_dict(torch.load(ckpt_fn, map_location='cpu'))\n",
    "dataset = JGMaskedDataset(is_valid=True, tokenizer=tokenizer, augment_param=config.aug)\n",
    "augmentor = dataset.augmentor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_input_format(roll_array:np.ndarray):\n",
    "  assert roll_array.ndim == 2\n",
    "  roll_list = roll_array.tolist()\n",
    "  roll_list = [ ['start'] * len(roll_list[0])] + roll_list + [ ['end'] * len(roll_list[0])]\n",
    "  tokens = tokenizer(roll_list)\n",
    "  return torch.LongTensor(tokens)\n",
    "\n",
    "def aug_form_to_input_form(x:torch.Tensor):\n",
    "  assert x.ndim == 3\n",
    "  return x.permute(2,0,1).flatten(0,1)\n",
    "\n",
    "x = dataset.entire_segments[0]['daegeum']\n",
    "x = convert_to_input_format(x)\n",
    "x, loss_mask = augmentor.mask_except_start_beat(x)\n",
    "x, loss_mask = aug_form_to_input_form(x), aug_form_to_input_form(loss_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_str = open('music_score/chwipunghyeong_gen.txt').read()\n",
    "piece = JeongganPiece(None, gen_str=gen_str, inst_list=['piri'])\n",
    "\n",
    "x = piece.convert_tokens_to_roll(piece.sliced_parts_by_measure[30]['piri'], 'piri')\n",
    "x = convert_to_input_format(x)\n",
    "# x, loss_mask = augmentor.mask_except_start_beat(x)\n",
    "x, loss_mask = augmentor.mask_except_note_onset(x)\n",
    "x, loss_mask = aug_form_to_input_form(x), aug_form_to_input_form(loss_mask)\n",
    "\n",
    "x = bert_inference(model, x, loss_mask, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from  torch.nn.functional import one_hot\n",
    "\n",
    "plt.imshow(one_hot(x[:, 0]).T, aspect='auto', interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_inference(model, x, loss_mask, n):\n",
    "  with torch.inference_mode():\n",
    "    pitch_mask_remaining = loss_mask[:,0].sum()\n",
    "    while pitch_mask_remaining >0:\n",
    "      pred, _ = model(x.unsqueeze(0))\n",
    "      pred = pred[0] # (T, C)\n",
    "      pitch_pred = pred[:, 0]\n",
    "      pitch_mask = loss_mask[:, 0]\n",
    "\n",
    "      is_masked = pitch_mask==1\n",
    "      pitch_masked_idx = torch.where(is_masked)[0]\n",
    "      \n",
    "      masked_pitch_prob = pitch_pred[is_masked].softmax(dim=-1)\n",
    "      high_prob_idx = masked_pitch_prob.max(dim=-1).values.argsort(descending=True)[:n]\n",
    "      high_prob_pitches = masked_pitch_prob[high_prob_idx].argmax(dim=-1)\n",
    "      \n",
    "      selected_idx = pitch_masked_idx[high_prob_idx]\n",
    "      x[selected_idx, 0] = high_prob_pitches \n",
    "      loss_mask[selected_idx, 0] = 0\n",
    "      pitch_mask_remaining = loss_mask[:,0].sum()\n",
    "    \n",
    "    orn_mask_remaining = loss_mask[:,1].sum()  \n",
    "    while orn_mask_remaining >0:\n",
    "      pred, _ = model(x.unsqueeze(0))\n",
    "      pred = pred[0] # (T, C)\n",
    "      orn_pred = pred[:, 1]\n",
    "      orn_mask = loss_mask[:, 1]\n",
    "\n",
    "      is_masked = orn_mask==1\n",
    "      orn_masked_idx = torch.where(is_masked)[0]\n",
    "      \n",
    "      masked_orn_prob = orn_pred[is_masked].softmax(dim=-1)\n",
    "      high_prob_idx = masked_orn_prob.max(dim=-1).values.argsort(descending=True)[:n]\n",
    "      high_prob_orns = masked_orn_prob[high_prob_idx].argmax(dim=-1)\n",
    "      \n",
    "      selected_idx = orn_masked_idx[high_prob_idx]\n",
    "      x[selected_idx, 1] = high_prob_orns \n",
    "      loss_mask[selected_idx, 1] = 0\n",
    "      orn_mask_remaining = loss_mask[:,1].sum()\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3\n",
    "pitch_mask_remaining = loss_mask[:,0].sum()\n",
    "while pitch_mask_remaining >0:\n",
    "  pred, _ = model(x.unsqueeze(0))\n",
    "  pred = pred[0] # (T, C)\n",
    "  pitch_pred = pred[:, 0]\n",
    "  pitch_mask = loss_mask[:, 0]\n",
    "\n",
    "  is_masked = pitch_mask==1\n",
    "  pitch_masked_idx = torch.where(is_masked)[0]\n",
    "  \n",
    "  masked_pitch_prob = pitch_pred[is_masked].softmax(dim=-1).detach()\n",
    "  high_prob_idx = masked_pitch_prob.max(dim=-1).values.argsort(descending=True)[:n]\n",
    "  high_prob_pitches = masked_pitch_prob[high_prob_idx].argmax(dim=-1)\n",
    "  \n",
    "  selected_idx = pitch_masked_idx[high_prob_idx]\n",
    "  x[selected_idx, 0] = high_prob_pitches \n",
    "  loss_mask[selected_idx, 0] = 0\n",
    "  pitch_mask_remaining = loss_mask[:,0].sum()\n",
    "\n",
    "orn_mask_remaining = loss_mask[:,1].sum()  \n",
    "while orn_mask_remaining >0:\n",
    "  pred, _ = model(x.unsqueeze(0))\n",
    "  pred = pred[0] # (T, C)\n",
    "  orn_pred = pred[:, 1]\n",
    "  orn_mask = loss_mask[:, 1]\n",
    "\n",
    "  is_masked = orn_mask==1\n",
    "  orn_masked_idx = torch.where(is_masked)[0]\n",
    "  \n",
    "  masked_orn_prob = orn_pred[is_masked].softmax(dim=-1).detach()\n",
    "  high_prob_idx = masked_orn_prob.max(dim=-1).values.argsort(descending=True)[:n]\n",
    "  high_prob_orns = masked_orn_prob[high_prob_idx].argmax(dim=-1)\n",
    "  \n",
    "  selected_idx = orn_masked_idx[high_prob_idx]\n",
    "  x[selected_idx, 1] = high_prob_orns \n",
    "  loss_mask[selected_idx, 1] = 0\n",
    "  orn_mask_remaining = loss_mask[:,1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import music21\n",
    "import copy\n",
    "from typing import List\n",
    "from sejong_music.jeonggan_utils import JGConverter, GencodeConverter, RollToJGConverter\n",
    "from sejong_music.jg_to_staff_converter import JGToStaffConverter\n",
    "\n",
    "\n",
    "roll = tokenizer.decode(x)\n",
    "\n",
    "converter = RollToJGConverter()\n",
    "jg_omr_str = converter(roll)\n",
    "gen_str = GencodeConverter.convert_lines_to_gencode(jg_omr_str.split('\\n'))\n",
    "staff_converter = JGToStaffConverter()\n",
    "mnotes, score = staff_converter(gen_str)\n",
    "\n",
    "org_token = piece.sliced_parts_by_measure[30]['piri']\n",
    "org_nots, org_score = staff_converter(org_token)\n",
    "\n",
    "total_score = music21.stream.Score()\n",
    "total_score.insert(0, score)\n",
    "total_score.insert(0, org_score)\n",
    "total_score.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jg_omr_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sejong_music.jg_code import JeongganPiece\n",
    "\n",
    "JeongganPiece('music_score/chwipunghyeong.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('music_score/chwipunghyeong.txt') as f:\n",
    "  jg_omr_str = f.read()\n",
    "# jg_omr_str.split('\\n')\n",
    "gen_str =GencodeConverter.convert_lines_to_gencode(jg_omr_str.split('\\n'))\n",
    "gen_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_mapping = {'배대':'배황', '배협':'배태', '배유':'배중', '배이':'배임', '배무':'배남',\n",
    "'대':'황', '협':'태', '유':'중', '이':'임', '무':'남', '청대':'청황', '청협':'청태'}\n",
    "\n",
    "outputs = []\n",
    "for token in gen_str.split(' '):\n",
    "  if token in pitch_mapping:\n",
    "    outputs.append(pitch_mapping[token])\n",
    "  else:\n",
    "    outputs.append(token)\n",
    "outputs = ' '.join(outputs)\n",
    "\n",
    "with open('music_score/chwipunghyeong_gen.txt', 'w') as f:\n",
    "  f.write(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_token = dataset.all_pieces[0].sliced_parts_by_measure[0]['daegeum']\n",
    "org_notes, org_score = staff_converter(org_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import music21\n",
    "total_score = music21.stream.Score()\n",
    "\n",
    "total_score.insert(0, score)\n",
    "total_score.insert(0, org_score)\n",
    "total_score.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_pitch_prob.max(dim=-1).values.argsort(descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(masked_pitch_prob.detach().cpu().numpy().T, aspect='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.squeeze().shape, (loss_mask==1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.squeeze()[loss_mask==1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_token_prob = pred.squeeze()[loss_mask==1].softmax(dim=-1).detach()\n",
    "masked_token_prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(pred.squeeze()[loss_mask==1].softmax(dim=-1).detach().T)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SejongMusic-0Xd-sAL0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
