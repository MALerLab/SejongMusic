{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/danbi/userdata/DANBI/gugakwon/Yeominrak\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%cd '/home/danbi/userdata/DANBI/gugakwon/Yeominrak'\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pathlib import Path\n",
    "import music21\n",
    "from music21 import converter, stream, note as m21_note \n",
    "from typing import List, Set, Dict, Tuple\n",
    "import torch\n",
    "from collections import defaultdict, Counter\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "from yeominrak_processing import AlignedScore, SamplingScore, pack_collate, ShiftedAlignedScore\n",
    "from model import Seq2seq, Converter, AttentionSeq2seq, QkvAttnSeq2seq, get_emb_total_size\n",
    "import random as random\n",
    "from loss import nll_loss\n",
    "from trainer import Trainer\n",
    "from decode import MidiDecoder\n",
    "from torch.nn.utils.rnn import pack_sequence, PackedSequence, pad_packed_sequence, pack_padded_sequence\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from omegaconf import OmegaConf\n",
    "from metric import make_dynamic_template, convert_note_to_sampling, get_similarity, get_correspondence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = OmegaConf.load('yamls/baseline.yaml')\n",
    "config = get_emb_total_size(config)\n",
    "device = 'cpu'\n",
    "val_dataset = ShiftedAlignedScore(is_valid= True, slice_measure_num=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_loader = DataLoader(val_dataset, batch_size=4, collate_fn=pack_collate, shuffle=False)\n",
    "model = QkvAttnSeq2seq(val_dataset.tokenizer, config.model).to(device)\n",
    "state = torch.load('best_model.pt')\n",
    "model.load_state_dict(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 160 0\n",
      "1 160 0\n",
      "2 156 4\n",
      "3 155 5\n",
      "4 59 101\n",
      "5 98 62\n",
      "6 159 1\n",
      "7 160 0\n"
     ]
    }
   ],
   "source": [
    "for i in range(8):\n",
    "  num = 0\n",
    "  for measure in val_dataset.measure_features[i]:\n",
    "    if measure == []:\n",
    "      num+=1\n",
    "  print(i, 160 -num, num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 51.0, 3.0, 0.0, 'strong'],\n",
       " [2, 51.0, 3.0, 3.0, 'middle'],\n",
       " [2, 51.0, 2.0, 6.0, 'strong'],\n",
       " [2, 48.0, 1.0, 8.0, 'middle'],\n",
       " [2, 46.0, 1.0, 9.0, 'weak']]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset.measure_features[2][40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similirity between 0 - 1 is 0.80625\n",
      "dymamic corresponse between 0 - 1 is 0.84375\n",
      "similirity between 2 - 3 is 0.92968\n",
      "dymamic corresponse between 2 - 3 is 0.91935\n",
      "similirity between 3 - 4 is 0.91102\n",
      "dymamic corresponse between 3 - 4 is 0.95339\n",
      "similirity between 4 - 5 is 0.91596\n",
      "dymamic corresponse between 4 - 5 is 0.92021\n",
      "similirity between 5 - 6 is 0.60238\n",
      "dymamic corresponse between 5 - 6 is 0.78061\n",
      "similirity between 6 - 7 is 0.9021\n",
      "dymamic corresponse between 6 - 7 is 0.91038\n"
     ]
    }
   ],
   "source": [
    "dynamic_template = make_dynamic_template(offset_list=val_dataset.offset_list)\n",
    "whole_part_sampled_notes = []\n",
    "for part_idx in range(8):\n",
    "  part_sampled_notes = [convert_note_to_sampling(measure, dynamic_template) for measure in val_dataset.measure_features[part_idx]]\n",
    "  whole_part_sampled_notes.append(part_sampled_notes)\n",
    "  \n",
    "idx_sample = [(0,1), (2,3), (3,4), (4,5), (5,6), (6,7)]\n",
    "for idx_1, idx_2 in idx_sample:\n",
    "  print('similirity between', idx_1,'-',idx_2, 'is', round(get_similarity(whole_part_sampled_notes, idx_1, idx_2), 5))\n",
    "  print('dymamic corresponse between', idx_1, '-', idx_2, 'is', round(get_correspondence(whole_part_sampled_notes, idx_1, idx_2), 5))\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - 1 0.84375\n",
      "2 - 3 0.91935\n",
      "3 - 4 0.95339\n",
      "4 - 5 0.92021\n",
      "5 - 6 0.78061\n",
      "6 - 7 0.91038\n"
     ]
    }
   ],
   "source": [
    "def get_correspondence(idx_1, idx_2):\n",
    "  correspondence = []\n",
    "  for i in range(160):\n",
    "    first = whole_part_sampled_notes[idx_1][i]\n",
    "    second = whole_part_sampled_notes[idx_2][i]\n",
    "    # print(first)\n",
    "    if idx_1 in [2,3,4,5,6,7] or idx_2 in [4,5]:\n",
    "      if first[0]==['empty'] or second[0]==['empty']:\n",
    "        # print(first)\n",
    "        continue\n",
    "    strong_beat_a = []   \n",
    "    strong_beat_b = []\n",
    "    for j, note in enumerate(first):\n",
    "      # print(note)\n",
    "      if note[3] in ['strong', 'middle']:\n",
    "        strong_beat_a.append(note[1])\n",
    "    for j, note in enumerate(second):\n",
    "      if note[3] in ['strong', 'middle']:\n",
    "        strong_beat_b.append(note[1])\n",
    "    \n",
    "    measure_correspondence = sum([strong_beat_a[idx]==strong_beat_b[idx] for idx in range(len(strong_beat_a))])/len(strong_beat_a)\n",
    "    correspondence.append(measure_correspondence)\n",
    "   \n",
    "  return sum(correspondence)/len(correspondence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dynamic_template(offset_list,beat_sampling_num=6):\n",
    "  whole_dynamic_template = []\n",
    "  for part_idx in range(8):\n",
    "      frame = beat_sampling_num\n",
    "      if part_idx == 0:\n",
    "          # 세종실록악보 : 2.5/1.5, 1.5/1/1.5\n",
    "          dynamic_mapping = {0.0: 'strong', 2.5: 'strong', 1.5: 'middle', \\\n",
    "              0.5: 'weak', 1.0: 'weak', 2.0: 'weak', 3.0: 'weak',3.5: 'weak'}\n",
    "          frame = frame * 2 #세종실록인 경우는 frame이 두 배!\n",
    "      \n",
    "      elif part_idx == 1:\n",
    "          # 금합자보: 5/3, 3/2/3\n",
    "          dynamic_mapping = {0.0: 'strong', 5.0: 'strong', 3.0: 'middle',\\\n",
    "              1.0: 'weak', 2.0: 'weak', 4.0: 'weak', 6.0: 'weak', 7.0: 'weak',}\n",
    "      \n",
    "      elif part_idx in [2, 3, 4, 5]:\n",
    "          # 속악원보, 금보신증가령, 한금신보, 어은보: 6/4, 3/3/2/2 \n",
    "          dynamic_mapping = {0.0: 'strong', 6.0: 'strong', 3.0: 'middle', 8.0: 'middle', \\\n",
    "              1.0: 'weak', 2.0: 'weak', 4.0: 'weak', 5.0: 'weak', 7.0: 'weak', 9.0: 'weak'}\n",
    "      \n",
    "      elif part_idx in [6, 7]:\n",
    "          # 삼죽금보, 현행: 5/5, 3/2/2/3\n",
    "          dynamic_mapping = {0.0: 'strong', 5.0: 'strong', 3.0: 'middle', 7.0: 'middle',\\\n",
    "              1.0: 'weak', 2.0: 'weak', 4.0: 'weak', 6.0: 'weak', 8.0: 'weak', 9.0: 'weak'}\n",
    "      whole_measure_len = int(frame * offset_list[part_idx])\n",
    "      dynamic_list = []\n",
    "      for i in range(whole_measure_len):\n",
    "          dynamic = dynamic_mapping.get(float(i) / frame, 'pad')\n",
    "          dynamic_list.append(dynamic)\n",
    "      whole_dynamic_template.append(dynamic_list)\n",
    "  return whole_dynamic_template\n",
    "\n",
    "def convert_note_to_sampling(measure, dynamic_templates, beat_sampling_num = 6):\n",
    "  if len(measure) == 0:\n",
    "    return [['empty'] for _ in range(60)]  # 어차피, 4,5만 비어있으니까 괜찮을 것 같음! \n",
    "    \n",
    "  new_measure = []\n",
    "  for note in measure:\n",
    "    frame = int(beat_sampling_num * note[2])\n",
    "    if note[0]==0:\n",
    "      frame = frame * 2 # beat strength는 절대값?\n",
    "    # [part_idx, pitch, onset]\n",
    "    new_note = [[note[0], note[1], 1]] + [[note[0], note[1], 0]]*(frame-1)\n",
    "    new_measure += new_note\n",
    "      \n",
    "  dynamic_template = dynamic_templates[new_measure[0][0]] #part_idx\n",
    "  dynamic_template = dynamic_template * (len(new_measure)//len(dynamic_template))\n",
    "  new_measure_with_dynamic = []\n",
    "  # print(len(new_measure), len(dynamic_template))\n",
    "  for i, frame in enumerate(new_measure):\n",
    "    if len(new_measure) == len(dynamic_template):\n",
    "      new_frame = frame+[dynamic_template[i]]\n",
    "      new_measure_with_dynamic.append(new_frame)\n",
    "    else:\n",
    "      ValueError('len(new_measure) != len(dynamic_template)')\n",
    "  new_measure_with_dynamic\n",
    "\n",
    "  return new_measure_with_dynamic\n",
    "\n",
    "def get_similarity(idx_1, idx_2):\n",
    "  similarity = []\n",
    "  for i in range(160):\n",
    "    first = whole_part_sampled_notes[idx_1][i]\n",
    "    second = whole_part_sampled_notes[idx_2][i]\n",
    "    \n",
    "    if idx_1 in [2,3,4,5,6,7] or idx_2 in [4,5]:\n",
    "      if first[0]==['empty'] or second[0]==['empty']:\n",
    "        # print(first)\n",
    "        continue\n",
    "    measure_similarity = sum([note_1[1]==note_2[1] for note_1, note_2 in zip(first, second)])/len(first)\n",
    "    similarity.append(measure_similarity)\n",
    "   \n",
    "  return sum(similarity)/len(similarity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
